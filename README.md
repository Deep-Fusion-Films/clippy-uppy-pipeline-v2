Clippy Uppy Pipeline v2
AIâ€‘powered, eventâ€‘driven video ingestion and enrichment pipeline
Clippy Uppy Pipeline v2 is a modular, serverless, microserviceâ€‘based system for ingesting, processing, analysing, and enriching video content using Google Cloud and Gemini models.

It is designed for:

Highâ€‘volume ingestion

Realâ€‘time and batch enrichment

Multiâ€‘provider support (Getty, Newsflare, direct uploads)

Scalable, faultâ€‘tolerant processing

Deep metadata extraction using Gemini Flash and Pro Vision

Durable storage in Firestore + GCS

This repository contains all microservices, shared utilities, orchestrators, and documentation for the full pipeline.

ğŸ§± Architecture Overview
Code
GCS Upload / Provider Event
          â”‚
          â–¼
   ingest-service
          â”‚
          â–¼
 audio-extract-service
          â”‚
          â–¼
audio-transcribe-service
          â”‚
          â–¼
 frame-sample-service
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ enrich-service (Flash)                   â”‚
 â”‚ enrich-pro-service (Pro Vision)          â”‚
 â”‚ batch-enrich-service (Gemini Batch API)  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
      store-service
          â”‚
          â–¼
   Firestore + GCS JSON
Orchestration is handled by:

orchestrator â†’ realâ€‘time Flash pipeline

batch-orchestrator â†’ Batch API + Pro Vision pipelines

ğŸ“¦ Repository Structure
Code
clippy-uppy-pipeline-v2/
â”‚
â”œâ”€â”€ ingest-service/              # Normalises ingest events and starts pipeline
â”œâ”€â”€ audio-extract-service/       # Extracts audio using FFmpeg
â”œâ”€â”€ audio-transcribe-service/    # Transcribes audio using Gemini Audio
â”œâ”€â”€ frame-sample-service/        # Extracts frames (1 FPS, max 50)
â”‚
â”œâ”€â”€ enrich-service/              # Gemini Flash enrichment
â”œâ”€â”€ enrich-pro-service/          # Gemini Pro Vision enrichment
â”œâ”€â”€ batch-enrich-service/        # Gemini Batch API enrichment (backfills)
â”‚
â”œâ”€â”€ store-service/               # Writes metadata to Firestore + GCS
â”‚
â”œâ”€â”€ orchestrator/                # Real-time Flash pipeline controller
â”œâ”€â”€ batch-orchestrator/          # Batch + Pro Vision pipeline controller
â”‚
â”œâ”€â”€ shared/                      # Shared utilities (GCS, FFmpeg, Gemini, Pub/Sub)
â”‚
â””â”€â”€ documentation/               # Architecture, message contracts, service docs
Each service is a standalone Cloud Run microservice with:

main.py (FastAPI entrypoint)

Dockerfile

requirements.txt

utils.py

Serviceâ€‘specific logic

ğŸ”„ Pipeline Flow (High-Level)
1. Ingest
ingest-service receives GCS events or provider metadata, normalises them into a Unified Ingest Format, and publishes to:

Code
pipeline.v2.start
2. Audio Extraction
audio-extract-service:

Downloads video

Extracts audio via FFmpeg

Uploads audio

Publishes to pipeline.v2.audio.transcribe

3. Transcription
audio-transcribe-service:

Downloads audio

Sends to Gemini Audio

Uploads transcript

Publishes to pipeline.v2.frame.sample

4. Frame Sampling
frame-sample-service:

Extracts 1 FPS frames (max 50)

Uploads frames

Publishes to pipeline.v2.enrich

5. Enrichment
Three possible paths:

Flash (realâ€‘time)
enrich-service â†’ Gemini Flash
Produces lightweight metadata.

Pro Vision (deep analysis)
enrich-pro-service â†’ Gemini 1.5 Pro Vision
Produces richer metadata (timeline, transitions, weather, etc.)

Batch API (bulk backfills)
batch-enrich-service â†’ Gemini Batch API
Processes large volumes cheaply.

6. Storage
store-service writes:

Structured metadata â†’ Firestore

Full JSON payload â†’ GCS

ğŸ§  Orchestration
Realâ€‘time Flash pipeline
Handled by orchestrator:

Code
pipeline.v2.start â†’ audio.extract â†’ audio.transcribe â†’ frame.sample â†’ enrich â†’ store
Batch + Pro Vision pipeline
Handled by batch-orchestrator:

Code
pipeline.v2.start â†’ enrich.pro OR batch.enrich â†’ store
Routing rules can be extended (e.g., â€œsend Newsflare to Pro Visionâ€).

ğŸ§ª Local Development
Run any service locally:
bash
cd ingest-service
pip install -r requirements.txt
uvicorn main:app --reload --port 8080
Build Docker image:
bash
docker build -t ingest-service .
Run with Docker:
bash
docker run -p 8080:8080 ingest-service
â˜ï¸ Deployment (Cloud Run)
Deploy any service:

bash
gcloud run deploy ingest-service \
  --source ingest-service \
  --region europe-west1 \
  --platform managed \
  --allow-unauthenticated
Repeat for each service.

ğŸ”§ Environment Variables
Each service uses a subset of:

Variable	Description
GCP_PROJECT	GCP project ID
PIPELINE_START_TOPIC	Ingest â†’ Orchestrator
AUDIO_EXTRACT_TOPIC	Orchestrator â†’ Audio Extract
AUDIO_TRANSCRIBE_TOPIC	Audio Extract â†’ Transcribe
FRAME_SAMPLE_TOPIC	Transcribe â†’ Frame Sample
ENRICH_TOPIC	Frame Sample â†’ Flash
PRO_ENRICH_TOPIC	Frame Sample â†’ Pro Vision
BATCH_ENRICH_TOPIC	Batch API jobs
STORE_TOPIC	Enrich â†’ Store
METADATA_BUCKET	GCS bucket for metadata JSON
ğŸ§© Shared Utilities
The shared/ directory contains:

ffmpeg.py â€” audio + frame extraction helpers

gcs.py â€” GCS download/upload utilities

gemini.py â€” Gemini Flash, Pro Vision, Audio, Batch wrappers

pubsub.py â€” Pub/Sub publish + decode helpers

schemas.py â€” shared Pydantic models

utils.py â€” logging, ID generation, helpers

This prevents duplication across services.

ğŸ—ºï¸ Documentation
See the documentation/ folder for:

Architecture overview

Pipeline flow

Perâ€‘service documentation

Message contracts

Deployment guide

Error handling

Scaling and performance

Roadmap
